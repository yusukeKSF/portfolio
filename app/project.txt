1. ç›®çš„
- Python ã§è‡ªå‹•ä»•è¨³ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ç›®æ¨™ã«ã—ã¦ãŠã‚Šç¾åœ¨æœ€çµ‚èª¿æ•´ã«å…¥ã£ã¦ãŠã‚Šã¾ã™ã€‚Webã‚¢ãƒ—ãƒªã¨ã—ã¦å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãŠã‚Šã€UXã®å¯¾å¿œã‚‚è¦–é‡ã«å…¥ã‚Œã¦ã„ã¾ã™ã€‚

2. 


### gpt_journal_translation


### send_camera_image.py

import requests

# ğŸ“¸ é€ä¿¡ã—ãŸã„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
image_path = "images/test5.png"  # ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š

# ğŸ¯ FastAPIã‚µãƒ¼ãƒãƒ¼ã®URLï¼ˆãƒ­ãƒ¼ã‚«ãƒ« or ãƒ‡ãƒ—ãƒ­ã‚¤å…ˆã«å¿œã˜ã¦ä¿®æ­£ï¼‰
url = "http://localhost:8000/camera/convert_and_write"

# ğŸ“¤ ç”»åƒã‚’multipart/form-dataã§é€ä¿¡
with open(image_path, "rb") as f:
    files = {"file": (image_path, f, "image/jpeg")}
    response = requests.post(url, files=files)

# ğŸ–¨ çµæœã‚’è¡¨ç¤º
print("ğŸ“¬ ã‚µãƒ¼ãƒãƒ¼å¿œç­”:", response.status_code)
print(response.json())


### app/main.py

from fastapi import FastAPI, UploadFile, File
from fastapi import Body
from app.service.ocr import extract_text_from_image
from app.service.gpt import generate_journal_entries
from app.service.sheets import write_entries_to_sheet
from app.schemas import GPTRequest, WriteRequest
from app.handlers import sales, purchase, depreciation, asset_purchase, supplies_purchase
from pydantic import BaseModel
from app.service import gpt
from app.routes import camera_ocr_router


app = FastAPI()

# ãƒ«ãƒ¼ã‚¿ãƒ¼ç™»éŒ²
app.include_router(sales.router, prefix="/journal")
app.include_router(purchase.router, prefix="/journal")
app.include_router(depreciation.router, prefix="/journal")
app.include_router(asset_purchase.router, prefix="/journal")
app.include_router(supplies_purchase.router, prefix="/journal")
app.include_router(gpt.router)
app.include_router(camera_ocr_router.router, prefix="/camera")



class GPTRequest(BaseModel):
    text: str
    
class WriteRequest(BaseModel):
    date: str
    summary: str
    entries: list[dict]

@app.get("/")
def root():
    return {"message": "FastAPI is running."}

@app.post("/ocr")
async def ocr_endpoint(file: UploadFile = File(...)):
    contents = await file.read()
    file_path = f"/tmp/{file.filename}"
    with open(file_path, "wb") as f:
        f.write(contents)
    text = extract_text_from_image(file_path)
    return {"text": text}

@app.post("/generate")
def generate_endpoint(req: GPTRequest):
    journal = generate_journal_entries(req.text)
    return journal

@app.post("/write")
def write_endpoint(req: WriteRequest):
    entries = [entry.dict() for entry in req.entries]
    write_entries_to_sheet(entries, req.date, req.summary)
    return {"status": "success", "message": "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ"}

# /generate ã¨ /write ã‚’1å›ã®POSTã§å®Œäº†ã™ã‚‹ãŸã‚çµ±åˆ
@app.post("/convert_and_write")
def convert_and_write(req: GPTRequest):
    journal = generate_journal_entries(req.text)
    entries = [entry for entry in journal["entries"]]
    write_req = WriteRequest(
        date=journal["date"],
        summary=journal["summary"],
        entries=entries
    )
    write_entries_to_sheet(
        entries=write_req.entries,
        date=write_req.date,
        summary=write_req.summary
    )
    return {"status": "success", "message": "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ"}



###app/schemas.py

from pydantic import BaseModel
from typing import List, Optional, Literal



class Entry(BaseModel):
    debit: str
    credit: str
    amount: int

class GPTRequest(BaseModel):
    text: str

class WriteRequest(BaseModel):
    date: str
    summary: str
    entries: List[Entry]


class SalesRequest(BaseModel):
    type: Literal["sales"]
    date: str
    summary: str
    customer: str
    amount: float
    entries: List[Entry]

class PurchaseRequest(BaseModel):
    type: Literal["purchase"]
    date: str
    summary: str
    supplier: str
    amount: float
    entries: List[Entry]

class SuppliesPurchaseRequest(BaseModel):
    type: Literal["supplies_purchase"]
    date: str
    summary: str
    supplier: Optional[str]
    amount: float
    entries: List[Entry]

class AssetPurchaseRequest(BaseModel):
    type: Literal["asset_purchase"]
    date: str
    summary: str
    asset_name: str
    amount: float
    entries: List[Entry]

class DepreciationRequest(BaseModel):
    type: Literal["depreciation"]
    date: str
    summary: str
    asset_name: str
    acquisition_date: str
    closing_date: str
    calc_closing_date: Optional[str] = None
    method: str
    amount: float
    life: int
    target_year: Optional[str] = None
    current_volume: Optional[float] = None
    total_volume: Optional[float] = None
    entries: List[Entry]


### app/logger.py
# ãƒ­ã‚°ã‚’ä½œæˆã—è¿½è·¡å¯èƒ½ã«ã—ã¦ãŠã
# gpt.py ã§ï¼”ç®‡æ‰€ã§ãƒ­ã‚°è¨˜å…¥

import os
from datetime import datetime
from pathlib import Path

LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)

def save_log(content: str, prefix: str = "log") -> str:
    """
    ä»»æ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ timestamp ä»˜ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    Returns: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆstrï¼‰
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = LOG_DIR / f"{prefix}_{timestamp}.txt"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"ğŸ“„ ãƒ­ã‚°ä¿å­˜: {filename}")
    return str(filename)

def save_json(data: dict, prefix: str = "gpt_output") -> str:
    """
    dict ã‚’ JSONå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã™ã‚‹ã€‚
    """
    import json
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = LOG_DIR / f"{prefix}_{timestamp}.json"
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ JSONãƒ­ã‚°ä¿å­˜: {filename}")
    return str(filename)


### app/utils.py
# æ—¥ä»˜è£œå®Œã€€ ä¼šè¨ˆæœŸé–“ã‚„æ±ºç®—æ—¥ã®è£œå®ŒãŒè¡Œã‚ã‚Œã‚‹

import re
from datetime import datetime

def extract_fiscal_mmdd_period(text: str) -> tuple[str | None, str | None]:
    """
    ä¾‹ï¼šã€Œ4æœˆ1æ—¥ã‹ã‚‰3æœˆ31æ—¥ã¾ã§ã®ä¼šè¨ˆå¹´åº¦ã€ã®ã‚ˆã†ãªæ–‡ã‹ã‚‰ã€
    é–‹å§‹ãƒ»çµ‚äº†æ—¥ï¼ˆMM-DDå½¢å¼ï¼‰ã‚’æŠ½å‡ºã€‚
    Returns: (start_mmdd, end_mmdd)
    """
    pattern = r"(\d{1,2})æœˆ(\d{1,2})æ—¥ã‹ã‚‰(\d{1,2})æœˆ(\d{1,2})æ—¥"
    match = re.search(pattern, text)
    if match:
        start = f"{int(match.group(1)):02d}-{int(match.group(2)):02d}"
        end = f"{int(match.group(3)):02d}-{int(match.group(4)):02d}"
        return start, end
    return None, None

def derive_calc_closing_date(acquisition_date: str, fiscal_end_mmdd: str) -> str | None:
    """
    è³‡ç”£å–å¾—æ—¥ã¨ä¼šè¨ˆæœŸé–“ã®çµ‚äº†MM-DDã‹ã‚‰ã€
    åˆå¹´åº¦ã®æ±ºç®—æ—¥ï¼ˆYYYY-MM-DDï¼‰ã‚’å°å‡ºã€‚
    - ä¼šè¨ˆå¹´åº¦ãŒ1æœˆé–‹å§‹ä»¥å¤–ã®å ´åˆã€æ±ºç®—å¹´ã¯ã€ŒæœŸé¦–ã®å¹´ + 1ã€
    """
    try:
        acq_date = datetime.strptime(acquisition_date, "%Y-%m-%d")
        fiscal_month, fiscal_day = map(int, fiscal_end_mmdd.split("-"))

        # ä¼šè¨ˆæœŸé–“ã®çµ‚äº†æ—¥ãŒ 1æœˆã€œ12æœˆä»¥å¤– â†’ ç¿Œå¹´ã‚’æ±ºç®—å¹´ã¨ã™ã‚‹
        # ä¾‹ï¼š2025-04-01 å–å¾— â†’ æ±ºç®—æ—¥ 2026-03-31
        if acq_date.month > fiscal_month or (acq_date.month == fiscal_month and acq_date.day > fiscal_day):
            closing_year = acq_date.year + 1
        else:
            closing_year = acq_date.year

        return f"{closing_year}-{fiscal_month:02d}-{fiscal_day:02d}"

    except Exception as e:
        print(f"âŒ calc_closing_date æ¨å®šå¤±æ•—: {e}")
        return None


### app/handlers/asset_purchase.py

from fastapi import APIRouter
from app.schemas import AssetPurchaseRequest

router = APIRouter()

@router.post("/asset_purchase")
def handle_asset(data: AssetPurchaseRequest):
    print("\nâœ… å›ºå®šè³‡ç”£è³¼å…¥å–å¼•ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")
    print("ğŸ“… æ—¥ä»˜:", data.date)
    print("ğŸ–‹ è³‡ç”£å:", data.asset_name)
    print("ğŸ“ æ¦‚è¦:", data.summary)
    for entry in data.entries:
        print(f"  å€Ÿæ–¹: {entry.debit}, è²¸æ–¹: {entry.credit}, é‡‘é¡: {entry.amount}")
    return {"status": "success", "message": "asset_purchase å–å¼•ã‚’æ­£å¸¸ã«å—ä¿¡ã—ã¾ã—ãŸã€‚"}


### app/handlers/depreciation.py

from fastapi import APIRouter
from app.schemas import DepreciationRequest

router = APIRouter()

@router.post("/depreciation")
def handle_depreciation(data: DepreciationRequest):
    print("\nâœ… æ¸›ä¾¡å„Ÿå´ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")
    print("ğŸ“… æ—¥ä»˜:", data.target_year)
    print("ğŸ“ æ¦‚è¦:", data.summary)
    print("ğŸ§® å„Ÿå´æ–¹æ³•:", data.method)
    print("ğŸ“¦ å–å¾—é¡:", data.amount)
    print("ğŸ“† å–å¾—æ—¥:", data.acquisition_date)
    print("ğŸ“† æ±ºç®—æ—¥:", data.closing_date)
    if data.calc_closing_date:
        print("ğŸ“† åˆå¹´åº¦æ±ºç®—æ—¥:", data.calc_closing_date)
    print("ğŸ§¾ è€ç”¨å¹´æ•°:", data.life)
    if data.target_year:
        print("ğŸ” å¯¾è±¡å¹´åº¦:", data.target_year)

    for entry in data.entries:
        print(f"  å€Ÿæ–¹: {entry.debit}, è²¸æ–¹: {entry.credit}, é‡‘é¡: {entry.amount}")
    total = sum(e.amount for e in data.entries)
    print(f"ğŸ’° åˆè¨ˆæ¸›ä¾¡å„Ÿå´è²»ï¼ˆã‚¨ãƒ³ãƒˆãƒªåˆè¨ˆï¼‰: {total}")
    return {"status": "success", "message": "depreciation å–å¼•ã‚’æ­£å¸¸ã«å—ä¿¡ã—ã¾ã—ãŸã€‚"}



### app/handlers/purchase.py

from fastapi import APIRouter
from app.schemas import PurchaseRequest

router = APIRouter()

@router.post("/purchase")
def handle_purchase(data: PurchaseRequest):
    print("\nâœ… ä»•å…¥å–å¼•ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")
    print("ğŸ“… æ—¥ä»˜:", data.date)
    print("ğŸ¢ ä»•å…¥å…ˆ:", data.supplier)
    print("ğŸ“ æ¦‚è¦:", data.summary)
    for entry in data.entries:
        print(f"  å€Ÿæ–¹: {entry.debit}, è²¸æ–¹: {entry.credit}, é‡‘é¡: {entry.amount}")
    return {"status": "success", "message": "purchase å–å¼•ã‚’æ­£å¸¸ã«å—ä¿¡ã—ã¾ã—ãŸã€‚"}


### app/handlers/sales.py

from fastapi import APIRouter
from app.schemas import SalesRequest

router = APIRouter()

@router.post("/sales")    # @app.post â†’ @router.post  å…ƒã€…ã‚ã£ãŸ /journal ã‚‚å‰Šé™¤
def handle_sales(data: SalesRequest):
    print("\nâœ… å£²ä¸Šå–å¼•ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")
    print("ğŸ“… æ—¥ä»˜:", data.date)
    print("ğŸ§¾ é¡§å®¢å:", data.customer)
    print("ğŸ“ æ¦‚è¦:", data.summary)
    for entry in data.entries:
        print(f"  å€Ÿæ–¹: {entry.debit}, è²¸æ–¹: {entry.credit}, é‡‘é¡: {entry.amount}")
    return {"status": "success", "message": "sales å–å¼•ã‚’æ­£å¸¸ã«å—ä¿¡ã—ã¾ã—ãŸã€‚"}


### app/handlers/supplies_purchase.py

from fastapi import APIRouter
from app.schemas import SuppliesPurchaseRequest
                                        # â†‘
router = APIRouter()                    # ã“ã“ã®åå‰ã‚’åŒã˜ã«ã™ã‚‹ã€‚
                        # â†“ ãƒ«ãƒ¼ãƒˆURL     #
@router.post("/supplies_purchase")      # â†“
def handle_supplies(data: SuppliesPurchaseRequest):
    print("\nâœ… æ¶ˆè€—å“è³¼å…¥å–å¼•ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")
    print("ğŸ“… æ—¥ä»˜:", data.date)
    print("ğŸ“¦ æ¦‚è¦:", data.summary)
    for entry in data.entries:
        print(f"  å€Ÿæ–¹: {entry.debit}, è²¸æ–¹: {entry.credit}, é‡‘é¡: {entry.amount}")
    return {"status": "success", "message": "supplies_purchase å–å¼•ã‚’æ­£å¸¸ã«å—ä¿¡ã—ã¾ã—ãŸã€‚"}



#  app/routes/camera_ocr_router.py

from fastapi import APIRouter, UploadFile, File
import shutil
import tempfile
from app.service.ocr import extract_text_from_image
from app.service.gpt import generate_journal_entries, process_gpt_and_enrich
from app.service.sheets import write_entries_to_sheet




router = APIRouter()


# âœ…ã€è¿½åŠ ã€‘ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡ â†’ OCR â†’ GPT â†’ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿å‡¦ç†
@router.post("/convert_and_write")
async def process_ocr_and_send(file: UploadFile = File(...)):
    # âœ… ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp_file:
        shutil.copyfileobj(file.file, temp_file)
        temp_file_path = temp_file.name

    # âœ… OCRãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    text = extract_text_from_image(temp_file_path)

    # âœ… GPTã§ä»•è¨³ç”Ÿæˆ
    gpt_data = generate_journal_entries(text)

    # âœ… æ¸›ä¾¡å„Ÿå´è£œå®Œãªã© enrich å‡¦ç†
    enriched = process_gpt_and_enrich(gpt_data, text)

    # âœ… Google Sheets æ›¸ãè¾¼ã¿
    write_entries_to_sheet(
        entries=enriched["entries"],
        date=enriched["date"],
        summary=enriched["summary"]
    )

    return {"status": "success", "message": "æ’®å½±ç”»åƒã‹ã‚‰ä»•è¨³ã‚’ç™»éŒ²ã—ã¾ã—ãŸ"}


import numpy as np
from app.service.ocr import extract_text_from_frame
from app.routes.camera_ocr_router import generate_journal_entries, process_gpt_and_enrich
from app.service.sheets import write_entries_to_sheet

### å‡¦ç†ã‚’1ã¤ã®é–¢æ•°ã«ã‚«ãƒ—ã‚»ãƒ«åŒ–
# ã“ã®é–¢æ•°ã§ ç”»åƒã‹ã‚‰OCRå‡ºåŠ›ã€€â†’ GPTã«é€ä¿¡ â†’ æ¸›ä¾¡å„Ÿå´ã®é‡‘é¡ã®è£œå®Œ â†’ Google Sheets ã¸ã®æ›¸ãè¾¼ã¿ â†’ ãƒ­ã‚°ä¿å­˜
def process_ocr_and_send(frame: np.ndarray):
    # OCRå‡¦ç†
    ocr_text = extract_text_from_frame(frame)
    print("ğŸ“ OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:", ocr_text)

    # GPTå‡¦ç†
    journal = generate_journal_entries(ocr_text)

    # enrichï¼ˆæ¸›ä¾¡å„Ÿå´ãªã©ï¼‰
    enriched = process_gpt_and_enrich(journal, ocr_text)

    # æ›¸ãè¾¼ã¿å‡¦ç†
    write_entries_to_sheet(
        entries=enriched["entries"],
        date=enriched["date"],
        summary=enriched["summary"]
    )

    return {
        "status": "success",
        "message": "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ",
        "ocr_text": ocr_text,
        "journal": enriched
    }




### app/service/gpt.py

import os
import json
from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel
from app.service.sheets import write_entries_to_sheet
from app.service.depreciation_calc import calculate_depreciation_by_year
from app.utils import extract_fiscal_mmdd_period, derive_calc_closing_date
from app import logger
from fastapi import APIRouter
import numpy as np
from app.service.ocr import extract_text_from_frame
# from collections import defaultdict
from datetime import datetime




env = os.getenv("ENV", "production")
dotenv_file = f".env.{env}"
load_dotenv(dotenv_file)

api_key = os.getenv("OPENAI_API_KEY_PROJECT_VISION")
project_id = os.getenv("OPENAI_PROJECT_ID")


if not api_key:
    raise RuntimeError("âŒ OPENAI_API_KEY ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
if not project_id:
    raise RuntimeError("âŒ OPENAI_PROJECT_ID ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

client = OpenAI(api_key=api_key, project=project_id)

class GPTRequest(BaseModel):
    text: str
    
class WriteRequest(BaseModel):
    date: str
    summary: str
    entries: list[dict]


def generate_journal_entries(text: str) -> dict:
    print("ğŸ§  GPTã«å•ã„åˆã‚ã›ä¸­...")
    prompt = f"""
ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡ã¯OCRã§æŠ½å‡ºã•ã‚ŒãŸä¼šè¨ˆå–å¼•ã®è¨˜éŒ²ã§ã™ã€‚
ã“ã®æ–‡æ›¸ã‹ã‚‰å–å¼•å†…å®¹ã‚’èª­ã¿å–ã‚Šã€JSONå½¢å¼ã§ä¼šè¨ˆä»•è¨³ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ï¼š
- å‡ºåŠ›ã¯ JSON ã®ã¿ã€‚èª¬æ˜ã‚„æ³¨é‡ˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- é‡‘é¡ï¼ˆamountï¼‰ã¯åŠè§’æ•°å€¤ã€ã‚«ãƒ³ãƒã¯ä½¿ç”¨ã—ãªã„ã“ã¨ã€‚
- `entries` ã®é…åˆ—ã«ã€å€Ÿæ–¹ï¼ˆdebitï¼‰ã¨è²¸æ–¹ï¼ˆcreditï¼‰ã‚’åˆ†ã‘ã¦è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
- æ¸›ä¾¡å„Ÿå´è²»ãªã©ã®é‡‘é¡ã¯ã‚·ã‚¹ãƒ†ãƒ ãŒå¾Œã§è¨ˆç®—ã™ã‚‹ãŸã‚ã€`amount: 0` ã§æ§‹ã„ã¾ã›ã‚“ã€‚

# å–å¼•ã‚¿ã‚¤ãƒ—åˆ¤å®šï¼š
ä»¥ä¸‹ã® type ã®ã„ãšã‚Œã‹ã‚’åˆ¤å®šã—ã€å‡ºåŠ›ã«å«ã‚ã¦ãã ã•ã„ã€‚

- `"purchase"`ï¼šä»•å…¥å–å¼•ï¼ˆæ”¯æ‰•ã„æ–¹æ³•ã«ã‚ˆã‚Šã€Œç¾é‡‘ã€ã¾ãŸã¯ã€Œè²·æ›é‡‘ã€ï¼‰
- `"sales"`ï¼šå£²ä¸Šå–å¼•ï¼ˆå…¥é‡‘æ–¹æ³•ã«ã‚ˆã‚Šã€Œç¾é‡‘ã€ã¾ãŸã¯ã€Œå£²æ›é‡‘ã€ï¼‰
- `"supplies_purchase"`ï¼šæ¶ˆè€—å“ãªã©å³æ™‚è²»ç”¨å‡¦ç†ã®è³¼å…¥
- `"asset_purchase"`ï¼šå‚™å“ãªã©ã®å›ºå®šè³‡ç”£è³¼å…¥ï¼ˆæ¸›ä¾¡å„Ÿå´å¯¾è±¡ï¼‰
- `"depreciation"`ï¼šæ¸›ä¾¡å„Ÿå´ï¼ˆå›ºå®šè³‡ç”£ã®å¹´æ¬¡å„Ÿå´ï¼‰
- `"unknown"`ï¼šè©²å½“ãªã—ã¾ãŸã¯ä¸æ˜

# è£œè¶³ãƒ«ãƒ¼ãƒ«ï¼š

- ã€Œã€‡ã€‡ã‚’ä»•å…¥ã‚ŒãŸã€â†’ type: `"purchase"`ã€debit: `"ä»•å…¥"`
- ã€Œã€‡ã€‡ã‚’è³¼å…¥ã—ãŸã€â†’ contextã«å¿œã˜ã¦ `"supplies_purchase"` ã‹ `"asset_purchase"` ã«åˆ†é¡
- ã€Œæ›ã‘æ‰•ã„ã€ã€Œæœªæ‰•ã„ã€ç­‰ãŒã‚ã‚Œã°ï¼š
- purchaseç³»ã¯ credit: `"è²·æ›é‡‘"`ï¼ˆã¾ãŸã¯ `"æœªæ‰•é‡‘"`ï¼‰
- salesç³»ã¯ credit: `"å£²æ›é‡‘"`
- æ”¯æ‰•ãƒ»å—å–æ–¹æ³•ã®è¨˜è¼‰ãŒãªã„å ´åˆã€ç¾é‡‘å‡¦ç†ã¨ã™ã‚‹
- æ¸›ä¾¡å„Ÿå´æ™‚ã¯ debit: `"æ¸›ä¾¡å„Ÿå´è²»"`, credit: `"æ¸›ä¾¡å„Ÿå´ç´¯è¨ˆé¡"`
- å£²ä¸Šå–å¼•ï¼ˆtype: "sales"ï¼‰ã§ã¯ã€ã€Œå£²ä¸Šã€ã¯å¿…ãš `credit_entries` ã«å«ã‚ã¦ãã ã•ã„
- é‡‘é¡ãŒ20ä¸‡å††ã‚’è¶…ãˆã‚‹`"supplies_purchase"`ã®å ´åˆã¯ã€`"å‚™å“"`ã«åˆ†é¡ã™ã‚‹

---

# JSONå‡ºåŠ›å½¢å¼ï¼ˆå…¨ã‚¿ã‚¤ãƒ—å…±é€šï¼‰ï¼š

{{
  "type": "purchase"ï½œ"sales"ï½œ"depreciation"ï½œ"supplies_purchase"ï½œ"asset_purchase"ï½œ"unknown",
  "date": "YYYY-MM-DD",
  "summary": "å–å¼•ã®æ¦‚è¦ï¼ˆç°¡æ½”ã«ï¼‰",
  "supplier": "ä»•å…¥å…ˆåï¼ˆä»»æ„ï¼‰",
  "customer": "é¡§å®¢åï¼ˆä»»æ„ï¼‰",
  "asset_name": "è³‡ç”£åï¼ˆå¿…è¦ãªå ´åˆï¼‰",
  "acquisition_date": "å–å¾—æ—¥ï¼ˆå›ºå®šè³‡ç”£ç”¨ï¼‰",
  "calc_closing_date": "åˆå¹´åº¦æ±ºç®—æ—¥ï¼ˆæ¸›ä¾¡å„Ÿå´ç”¨ï¼‰",
  "target_year": "å„Ÿå´å¯¾è±¡å¹´åº¦æœ«ï¼ˆæ¸›ä¾¡å„Ÿå´ç”¨ï¼‰",
  "closing_date": "target_yearã¨åŒã˜å€¤ã‚’è¨­å®šï¼ˆå¿…é ˆï¼‰",
  "method": "å„Ÿå´æ–¹æ³•ï¼ˆä¾‹ï¼šå®šé¡æ³•ã€200%å®šç‡æ³•ã€ç´šæ•°æ³•ã€ç”Ÿç”£é«˜æ¯”ä¾‹æ³•ï¼‰",
  "amount": è³‡ç”£åŸä¾¡ï¼ˆæ•°å€¤ï¼‰,
  "life": è€ç”¨å¹´æ•°ï¼ˆæ•´æ•°ï¼‰,
  "current_volume": ç”Ÿç”£é‡ï¼ˆç”Ÿç”£é«˜æ¯”ä¾‹æ³•æ™‚ã®ã¿ï¼‰,
  "total_volume": ç·ç”Ÿç”£å¯èƒ½é‡ï¼ˆåŒä¸Šï¼‰,
  "debit_entries": [ {{"account": "å‹˜å®šç§‘ç›®", "amount": é‡‘é¡}} ],
  "credit_entries": [ {{"account": "å‹˜å®šç§‘ç›®", "amount": é‡‘é¡}} ]
}}

---

# æ¸›ä¾¡å„Ÿå´å–å¼•ï¼ˆtype: "depreciation"ï¼‰ã«é–¢ã™ã‚‹ç‰¹åˆ¥æŒ‡ç¤ºï¼š

- `summary`: ä¾‹ã€Œæ©Ÿæ¢°ã®æ¸›ä¾¡å„Ÿå´ã€ãªã©ç°¡æ½”ã«è¨˜è¿°
- `asset_name`: å¯¾è±¡è³‡ç”£ï¼ˆä¾‹ï¼š"æ©Ÿæ¢°", "è»Šä¸¡é‹æ¬å…·"ï¼‰
- `acquisition_date`: è³‡ç”£ã®å–å¾—æ—¥ï¼ˆYYYY-MM-DDï¼‰
- `calc_closing_date`: åˆå¹´åº¦ã®æ±ºç®—æ—¥ï¼ˆå–å¾—å¹´åº¦æœ«ï¼‰
- `target_year`: ä»Šå›å–å¾—ã—ãŸã„å„Ÿå´å¹´åº¦æœ«ï¼ˆä¾‹ï¼š2025-03-31ï¼‰
- `closing_date`: `target_year` ã¨åŒä¸€ã«è¨­å®šã™ã‚‹ã“ã¨
- `method`: å„Ÿå´æ–¹æ³•ï¼ˆ"å®šç‡æ³•" â†’ "200%å®šç‡æ³•" ã«å¤‰æ›ï¼‰
- `amount`: å–å¾—ä¾¡æ ¼ï¼ˆåŠè§’æ•°å€¤ï¼‰
- `life`: è€ç”¨å¹´æ•°ï¼ˆæ•´æ•°ï¼‰
- `entries`: é‡‘é¡ã¯ `0` ã§è‰¯ã„ï¼ˆå¾Œã§ã‚·ã‚¹ãƒ†ãƒ è¨ˆç®—ï¼‰

## ç”Ÿç”£é«˜æ¯”ä¾‹æ³•ã®å ´åˆï¼š
- `method`: "ç”Ÿç”£é«˜æ¯”ä¾‹æ³•"
- `current_volume`: å½“æœŸç”Ÿç”£é‡ï¼ˆæ•´æ•°ï¼‰
- `total_volume`: ç·ç”Ÿç”£å¯èƒ½é‡ï¼ˆæ•´æ•°ï¼‰
- `amount`: å–å¾—åŸä¾¡

æ³¨æ„äº‹é …ï¼š
- `calc_closing_date` ã¯è³‡ç”£ã‚’å–å¾—ã—ãŸåˆå¹´åº¦ã®æ±ºç®—æ—¥ã§ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›ã™ã‚‹æ±ºç®—æ—¥ã§ã™ï¼ˆé€šå¸¸ã¯å–å¾—æ—¥ã®å¹´ + ä¼šè¨ˆå¹´åº¦æœ«ï¼‰ã€‚
- `target_year` ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ¸›ä¾¡å„Ÿå´è²»ã‚’å–å¾—ã—ãŸã„å¹´åº¦ã®æ±ºç®—æ—¥ã§ã™ï¼ˆä¾‹ï¼š2025-03-31ï¼‰ã€‚
---

ä»¥ä¸‹ãŒå¯¾è±¡ã®å–å¼•æ–‡ã§ã™ï¼š

{text}
"""


    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ä¼šè¨ˆå£«ã§ã™ã€‚JSONã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªèª¬æ˜ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )

    content = response.choices[0].message.content
    print("ğŸ“¥ GPTå¿œç­”:", content)
    # ãƒ­ã‚°ã‚’ä¿å­˜
    logger.save_log(prompt, prefix="gpt_prompt")
    logger.save_log(content, prefix="gpt_response")

    try:
        return json.loads(content)
    except json.JSONDecodeError:
        raise ValueError("âŒ GPTã®å‡ºåŠ›ãŒJSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nå‡ºåŠ›:\n" + content)
    
    
# # é‡è¤‡ç§‘ç›®ã‚’åˆç®—   
# def convert_to_entries(debit_entries: list[dict], credit_entries: list[dict]) -> list[dict]:
#     entries = []
#     for debit in debit_entries:
#         entries.append({"debit": debit["account"], "credit": "", "amount": debit["amount"]})
#     for credit in credit_entries:
#         entries.append({"debit": "", "credit": credit["account"], "amount": credit["amount"]})
#     return entries

# def merge_entries_by_account(entries: list[dict]) -> list[dict]:
#     merged = defaultdict(int)
#     for entry in entries:
#         merged[entry["account"]] += entry["amount"]
#     return [{"account": acc, "amount": amt} for acc, amt in merged.items()]
    
# def merge_duplicate_entries(entries: list[dict]) -> list[dict]:
#     merged = defaultdict(int)
#     for entry in entries:
#         key = (entry['debit'], entry['credit'])
#         merged[key] += entry['amount']
#     return [
#         {"debit": k[0], "credit": k[1], "amount": v}
#         for k, v in merged.items()
#     ]


# æ¸›ä¾¡å„Ÿå´è²»ã®è‡ªå‹•å–å¾— (ä¼šè¨ˆå¹´åº¦è£œæ­£)â†’ é‡‘é¡åæ˜  â†’ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿ã¾ã§ä¸€è²«
def process_gpt_and_enrich(gpt_data: dict, ocr_text: str) -> dict:
    _, fiscal_end = extract_fiscal_mmdd_period(ocr_text)
    if not fiscal_end:
        fiscal_end = "03-31"

    
    logger.save_log(ocr_text, prefix="ocr_text")
    
    if gpt_data.get("type") == "depreciation":
        # æ¸›ä¾¡å„Ÿå´ â†’ ç‰¹åˆ¥å‡¦ç†ï¼ˆå˜ä¸€entryæ§‹é€ ï¼‰
        acquisition_date = gpt_data.get("acquisition_date")
        if acquisition_date and fiscal_end:
            gpt_data["calc_closing_date"] = derive_calc_closing_date(acquisition_date, fiscal_end)

        # fiscal yearè£œå®Œï¼ˆå¿…è¦ãªå ´åˆï¼‰
        if not gpt_data.get("closing_date"):
            gpt_data["closing_date"] = gpt_data.get("calc_closing_date")
        if not gpt_data.get("target_year"):
            gpt_data["target_year"] = gpt_data.get("closing_date")
            
        # æ¸›ä¾¡å„Ÿå´æ–¹æ³•ã®å¤‰æ›ï¼šå®šç‡æ³• â†’ 200%å®šç‡æ³•
        gpt_method = gpt_data.get("method", "")
        if gpt_method == "å®šç‡æ³•":
            gpt_data["method"] = "200%å®šç‡æ³•"

        # æ¸›ä¾¡å„Ÿå´è²»ã®è‡ªå‹•å–å¾—ï¼ˆæœ€å„ªå…ˆï¼‰
        try:
            dep = calculate_depreciation_by_year(
                starting_date=gpt_data.get("acquisition_date"),
                calc_closing_date=gpt_data.get("calc_closing_date"),
                method=gpt_data.get("method"),
                price=gpt_data.get("amount"),
                life=gpt_data.get("life"),
                target_year=gpt_data.get("target_year"),
                current_volume=gpt_data.get("current_volume"),
                total_volume=gpt_data.get("total_volume")
            )
        except Exception as e:
            print(f"âŒ æ¸›ä¾¡å„Ÿå´è²»å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            dep = None

        # è³‡ç”£åä»˜ãæ¸›ä¾¡å„Ÿå´ç´¯è¨ˆé¡ã¨ã—ã¦å¸³ç°¿ã‚’è¨˜éŒ²ã™ã‚‹
        credit_title = f"{gpt_data.get('asset_name', '')}æ¸›ä¾¡å„Ÿå´ç´¯è¨ˆé¡"
        gpt_data["entries"] = [{
            "debit": "æ¸›ä¾¡å„Ÿå´è²»",
            "credit": credit_title,
            "amount": dep if dep is not None else 0
        }]
    else:
        # è¤‡æ•°æ˜ç´°å‡¦ç† å‹˜å®šç§‘ç›®ã®åˆç®—ã¯è¡Œã‚ãªã„
        debit_entries = gpt_data.get("debit_entries", [])
        credit_entries = gpt_data.get("credit_entries", [])
        entries = []
        
        # å¯¾å¿œï¼šè²¸æ–¹ãŒ1ä»¶ãªã‚‰ç¹°ã‚Šè¿”ã—ã¦è¤‡æ•°å€Ÿæ–¹ã«å¯¾å¿œ
        if len(credit_entries) == 1 and len(debit_entries) > 1:
            credit = credit_entries[0]
            for debit in debit_entries:
                entries.append({
                    "debit": debit["account"],
                    "credit": credit["account"],
                    "amount": debit["amount"]
                })
        elif len(debit_entries) == 1 and len(credit_entries) > 1:
            debit = debit_entries[0]
            for credit in credit_entries:
                entries.append({
                    "debit": debit["account"],
                    "credit": credit["account"],
                    "amount": credit["amount"]
                })
        else:
            for debit in debit_entries:
                entries.append({
                    "debit": debit["account"],
                    "credit": "",
                    "amount": debit["amount"]
                })
            for credit in credit_entries:
                entries.append({
                    "debit": "",
                    "credit": credit["account"],
                    "amount": credit["amount"]
                })

        gpt_data["entries"] = entries

    logger.save_json(gpt_data, prefix="gpt_enriched")
    return gpt_data



# ä»•è¨³ã®ç”Ÿæˆã‹ã‚‰ã‚·ãƒ¼ãƒˆã¸ã®æ›¸ãè¾¼ã¿
def convert_and_write_from_text(text: str):
    journal = generate_journal_entries(text)
    enriched = process_gpt_and_enrich(journal, text)
    date = (
        enriched.get("target_year")
        or enriched.get("date")
        or enriched.get("acquisition_date")
        or enriched.get("calc_closing_date")
        or datetime.now().strftime("%Y-%m-%d")
    )
    write_entries_to_sheet(
        entries=enriched["entries"],
        date=date,
        summary=enriched["summary"],
        bordered=True
    )
    return {"status": "success", "message": "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ"}



# #ã‚«ãƒ¡ãƒ©ã®æ’®å½±ã‹ã‚‰OCRå‡¦ç† â†’ ã‚·ãƒ¼ãƒˆã¸ã®æ›¸ãè¾¼ã¿ã‚’è¡Œã†
# def process_ocr_and_send(frame: np.ndarray):
#     ocr_text = extract_text_from_frame(frame)
#     print("ğŸ“ OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:", ocr_text)
#     journal = generate_journal_entries(ocr_text)
#     enriched = process_gpt_and_enrich(journal, ocr_text)
#     date = (
#     enriched.get("target_year") or
#     enriched.get("closing_date") or
#     enriched.get("calc_closing_date") or
#     enriched.get("date") or
#     enriched.get("acquisition_date") or
#     datetime.now().strftime("%Y-%m-%d")
# )



#     write_entries_to_sheet(
#         entries=enriched["entries"],
#         date=date,
#         summary=enriched["summary"]
        # bordered=True
#     )
#     return {
#         "status": "success",
#         "message": "ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ",
#         "ocr_text": ocr_text,
#         "journal": enriched
#     }

# è¿½åŠ : convert_and_write ãƒ«ãƒ¼ãƒˆç”¨ FastAPI router
router = APIRouter()

@router.post("/convert_and_write")
def convert_and_write_endpoint(req: GPTRequest):
    return convert_and_write_from_text(req.text)



### app/services/depreciation_calc.py
# æ¸›ä¾¡å„Ÿå´è²»ã‚’å¤–éƒ¨ã‚µã‚¤ãƒˆã‹ã‚‰ Seleniumã‚’ä½¿ã£ã¦è‡ªå‹•å–å¾—

import time
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support import expected_conditions as EC
from googleapiclient.discovery import build
from google.oauth2.service_account import Credentials


def calculate_depreciation_by_year(
    starting_date: str,
    calc_closing_date: str,
    method: str,
    price: float,
    life: int,
    target_year: str,
    current_volume: float = None,
    total_volume: float = None
) -> float | None:
    """
    æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ã„ã¦ã€SeleniumçµŒç”±ã§æ¸›ä¾¡å„Ÿå´è²»ã‚’è‡ªå‹•å–å¾—ã™ã‚‹ã€‚

    Returns:
        æŒ‡å®šå¹´åº¦ã®æ¸›ä¾¡å„Ÿå´è²»ï¼ˆfloatï¼‰ã¾ãŸã¯ Noneï¼ˆå–å¾—å¤±æ•—æ™‚ï¼‰
    """
    try:
        options = Options()
        # options.add_argument("--headless") #ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã™ã‚‹ã“ã¨ã§é–‹ç™ºæ®µéšã«GUIç¢ºèªã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ 
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        # options.add_argument('--headless')  # é–‹ç™ºä¸­ã¯ GUI è¡¨ç¤ºã‚’æœ‰åŠ¹ã«ã™ã‚‹

        driver = webdriver.Chrome(options=options)
        driver.get("https://stylefunc287.xsrv.jp/php/dep.php")

        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã®è¦ç´ å–å¾—ã¨å…¥åŠ›
        starting_input = driver.find_element(By.ID, "startingDate")
        closing_input = driver.find_element(By.ID, "closingDate")
        driver.execute_script("arguments[0].value = arguments[1]", starting_input, starting_date) # JavaScript ã‚’ä½¿ã£ã¦å€¤ã‚’ç›´æ¥è¨­å®šã™ã‚‹ã€‚ã€€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾å­˜ã‚’é¿ã‘ã‚‹ã€‚ã€€ä»Šå›ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹webãƒšãƒ¼ã‚¸ã®æ—¥ä»˜å…¥åŠ›æ¬„ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯è‡ªå‹•å…¥åŠ›ã ã¨èª¤å…¥åŠ›ã‚’èµ·ã“ã—ã¦ã—ã¾ã†ã€‚
        driver.execute_script("arguments[0].value = arguments[1]", closing_input, calc_closing_date)
        Select(driver.find_element(By.ID, "cluculateMethod")).select_by_visible_text(method)
        driver.find_element(By.ID, "purchasePrice").send_keys(str(price))
        driver.find_element(By.ID, "usefulLife").send_keys(str(life))

        if method == "ç”Ÿç”£é«˜æ¯”ä¾‹æ³•":
            driver.find_element(By.ID, "currentVolume").send_keys(str(current_volume or ""))
            driver.find_element(By.ID, "totalVolume").send_keys(str(total_volume or ""))

        driver.find_element(By.ID, "submit").click()
        time.sleep(2)

        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰è©²å½“å¹´åº¦ã®æ¸›ä¾¡å„Ÿå´è²»ã‚’æŠ½å‡º
        rows = driver.find_elements(By.CSS_SELECTOR, "tbody.record tr")
        for row in rows:
            cols = row.find_elements(By.TAG_NAME, "td")
            if len(cols) >= 3 and cols[0].text.strip() == target_year:
                value = cols[2].text.replace(",", "")
                driver.quit()
                return float(value)

        driver.quit()
        return None

    except Exception as e:
        print(f"âŒ æ¸›ä¾¡å„Ÿå´è²»å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None


### app/service/ocr.py

import io
import os
from google.cloud import vision
from dotenv import load_dotenv
from pathlib import Path
from PIL import Image
import io
from google.cloud import vision
import cv2
import numpy as np


env = os.getenv("ENV", "production")
dotenv_file = f".env.{env}"
load_dotenv(dotenv_file)
# ç›¸å¯¾ãƒ‘ã‚¹ â†’ çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
# cred_path = Path(os.getenv("GOOGLE_APPLICATION_CREDENTIALS")).resolve()
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(cred_path)


client = vision.ImageAnnotatorClient()

def extract_text_from_frame(frame: np.ndarray) -> str:
    # OpenCVç”»åƒã‚’JPEGã«å¤‰æ›
    _, encoded_image = cv2.imencode('.jpg', frame)
    content = encoded_image.tobytes()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)

    if response.error.message:
        raise Exception(f"Vision API error: {response.error.message}")

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€ã¤ã«ã¾ã¨ã‚ã‚‹
    text = response.text_annotations[0].description if response.text_annotations else ""
    return text.strip()


def extract_text_from_image(image_path: str) -> str:
    print(f"ğŸ–¼ OCRå‡¦ç†é–‹å§‹: {image_path}")
    client = vision.ImageAnnotatorClient()

    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)

    if response.error.message:
        raise Exception(f"OCRã‚¨ãƒ©ãƒ¼: {response.error.message}")

    texts = response.text_annotations
    extracted = texts[0].description if texts else ''
    print("ğŸ“ OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:", extracted)
    return extracted



### app/service/sheets.py

import os
from typing import List
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from dotenv import load_dotenv

env = os.getenv("ENV", "production")
dotenv_file = f".env.{env}"
load_dotenv(dotenv_file)

# dotenv_path = os.path.join(os.path.dirname(__file__), "/Users/yusukek/Desktop/web_create/styleFunction/project_SF/journal_translate/gpt_journal_translation/.env.production")
# load_dotenv(dotenv_path)

SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
CREDENTIALS_PATH = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
SPREADSHEET_ID = os.getenv("SPREADSHEET_ID_PROJECT_VISION")
SHEET_NAME = os.getenv("SHEET_NAME", "ä»•è¨³å¸³")


def write_entries_to_sheet(entries: List[dict], date: str, summary: str, bordered=False):
    print("ğŸ“¤ Google Sheetsã¸æ›¸ãè¾¼ã¿é–‹å§‹")
    creds = Credentials.from_service_account_file(CREDENTIALS_PATH, scopes=SCOPES)
    gc = gspread.authorize(creds)
    worksheet = gc.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)

    values = []
    for i, entry in enumerate(entries):
        row = [
            date if i == 0 else "",
            entry["debit"],
            entry["amount"],
            entry["credit"],
            entry["amount"],
            summary if i == 0 else ""
        ]
        values.append(row)

    worksheet.append_rows(values, value_input_option="USER_ENTERED")
    print("âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä»•è¨³ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    # âœ… ç½«ç·šå‡¦ç†ãŒå¿…è¦ãªå ´åˆ
    if bordered:
        service = build("sheets", "v4", credentials=creds)
        sheet = service.spreadsheets()
        sheet_metadata = sheet.get(spreadsheetId=SPREADSHEET_ID).execute()
        sheet_id = next(s["properties"]["sheetId"] for s in sheet_metadata["sheets"] if s["properties"]["title"] == SHEET_NAME)
        start_row = worksheet.row_count - len(values) + 1
        end_row = worksheet.row_count

        requests = [{
            "updateBorders": {
                "range": {
                    "sheetId": sheet_id,
                    "startRowIndex": start_row - 1,
                    "endRowIndex": end_row,
                    "startColumnIndex": 0,
                    "endColumnIndex": 6
                },
                "top": {"style": "SOLID"},
                "bottom": {"style": "SOLID"},
                "left": {"style": "SOLID"},
                "right": {"style": "SOLID"},
                "innerHorizontal": {"style": "SOLID"},
                "innerVertical": {"style": "SOLID"}
            }
        }]
        sheet.batchUpdate(spreadsheetId=SPREADSHEET_ID, body={"requests": requests}).execute()
        print("ğŸ–‹ï¸ ç½«ç·šã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")




