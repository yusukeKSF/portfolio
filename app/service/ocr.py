### app/service/ocr.py

import io
import os
from google.cloud import vision
from dotenv import load_dotenv
from pathlib import Path
from PIL import Image
import io
from google.cloud import vision
import cv2
import numpy as np


env = os.getenv("ENV", "production")
dotenv_file = f".env.{env}"
load_dotenv(dotenv_file)
# ç›¸å¯¾ãƒ‘ã‚¹ â†’ çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
# cred_path = Path(os.getenv("GOOGLE_APPLICATION_CREDENTIALS")).resolve()
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(cred_path)


client = vision.ImageAnnotatorClient()

def extract_text_from_frame(frame: np.ndarray) -> str:
    # OpenCVç”»åƒã‚’JPEGã«å¤‰æ›
    _, encoded_image = cv2.imencode('.jpg', frame)
    content = encoded_image.tobytes()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)

    if response.error.message:
        raise Exception(f"Vision API error: {response.error.message}")

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€ã¤ã«ã¾ã¨ã‚ã‚‹
    text = response.text_annotations[0].description if response.text_annotations else ""
    return text.strip()


def extract_text_from_image(image_path: str) -> str:
    print(f"ğŸ–¼ OCRå‡¦ç†é–‹å§‹: {image_path}")
    client = vision.ImageAnnotatorClient()

    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)

    if response.error.message:
        raise Exception(f"OCRã‚¨ãƒ©ãƒ¼: {response.error.message}")

    texts = response.text_annotations
    extracted = texts[0].description if texts else ''
    print("ğŸ“ OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:", extracted)
    return extracted
